{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb8a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 (berita_terdahulu_grouping):\n",
      "  - Data asli: 1212\n",
      "  - Setelah cleaning: 1212\n",
      "\n",
      "Dataset 2 (berita_terkini_dengan_label):\n",
      "  - Data asli: 1078\n",
      "  - Setelah cleaning: 1078\n",
      "\n",
      "Dataset gabungan:\n",
      "  - Total data: 2290\n",
      "\n",
      "Kolom-kolom dalam dataset gabungan:\n",
      "['Title', 'Content', 'stemmed_text', 'faktor_str', 'label', 'date']\n",
      "\n",
      "Info dataset gabungan:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2290 entries, 0 to 2289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Title         2290 non-null   object\n",
      " 1   Content       2290 non-null   object\n",
      " 2   stemmed_text  2290 non-null   object\n",
      " 3   faktor_str    2290 non-null   object\n",
      " 4   label         2290 non-null   object\n",
      " 5   date          2290 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 107.5+ KB\n",
      "None\n",
      "\n",
      "Contoh 5 baris pertama dari dataset gabungan:\n",
      "                                               Title  \\\n",
      "0  Aliansi Buruh-Tani Ancam Mogok Massal Jika Per...   \n",
      "1  Terpopuler: Potensi Konflik Kepentingan Pimpin...   \n",
      "2  AHY Lanjutkan Kerja Sama dengan World Bank unt...   \n",
      "3  Bisnis di China Ngegas Lagi, Ekonomi Asia Bisa...   \n",
      "4  Pertamina International Shipping Tanggulangi I...   \n",
      "\n",
      "                                             Content  \\\n",
      "0  Sejumlah organisasi buruh  dan petani  menganc...   \n",
      "1  TEMPO.CO, Jakarta -Dugaan adanya potensi konfl...   \n",
      "2  Menteri Agraria dan Tata Ruang/Kepala Badan Pe...   \n",
      "3  Dana Moneter Internasional (International Mone...   \n",
      "4  Suara.com - PT Pertamina International Shippin...   \n",
      "\n",
      "                                        stemmed_text  \\\n",
      "0  organisasi buruh tani ancam gelar mogok massal...   \n",
      "1  tempo co jakarta duga potensi konflik penting ...   \n",
      "2  menteri agraria tata ruang kepala badan tanah ...   \n",
      "3  dana moneter internasional international monet...   \n",
      "4  suara com pt pertamina international shipping ...   \n",
      "\n",
      "                 faktor_str    label                            date  \n",
      "0            ['suku_bunga']  negatif          2023-03-15 00:32:32+00  \n",
      "1  ['suku_bunga', 'ekspor']  negatif          2023-03-15 23:00:00+00  \n",
      "2            ['suku_bunga']  negatif    Jumat, 30 Agu 2024 22:04 WIB  \n",
      "3  ['suku_bunga', 'ekspor']  positif  Selasa, 02 Mei  2023 16:35 WIB  \n",
      "4                 ['impor']  negatif          2023-03-27 04:43:38+00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load kedua dataset\n",
    "df_dataset1 = pd.read_csv(r'D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\berita_terdahulu_grouping.csv')\n",
    "df_dataset2 = pd.read_csv(r'D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\berita_terkini_dengan_label.csv')\n",
    "\n",
    "# 2. Sesuaikan nama kolom agar konsisten\n",
    "# Dataset 1 (berita_terdahulu_grouping.csv) sudah memiliki kolom yang sesuai\n",
    "# Hanya perlu rename Created_at ke date\n",
    "df_dataset1 = df_dataset1.rename(columns={'Created_at': 'date'})\n",
    "\n",
    "# Dataset 2 (berita_terkini_dengan_label.csv) perlu disesuaikan:\n",
    "# - title -> Title\n",
    "# - content -> Content  \n",
    "# - predicted_label -> label\n",
    "# - date tetap date\n",
    "df_dataset2 = df_dataset2.rename(columns={\n",
    "    'title': 'Title',\n",
    "    'content': 'Content',\n",
    "    'predicted_label': 'label'\n",
    "})\n",
    "\n",
    "# 3. Pilih hanya kolom yang dibutuhkan untuk kedua dataset\n",
    "required_columns = ['Title', 'Content', 'stemmed_text', 'faktor_str', 'label', 'date']\n",
    "\n",
    "df_dataset1_selected = df_dataset1[required_columns]\n",
    "df_dataset2_selected = df_dataset2[required_columns]\n",
    "\n",
    "# 4. Hapus duplikat dan nilai kosong dari kedua dataset\n",
    "# df_dataset1_clean = df_dataset1_selected.drop_duplicates(subset=['Content'])\n",
    "# df_dataset1_clean = df_dataset1_clean.dropna(subset=['Content', 'Title'])\n",
    "\n",
    "# df_dataset2_clean = df_dataset2_selected.drop_duplicates(subset=['Content'])\n",
    "# df_dataset2_clean = df_dataset2_clean.dropna(subset=['Content', 'Title'])\n",
    "\n",
    "# 5. Gabungkan kedua dataset (tanpa sampling)\n",
    "df_combined = pd.concat([df_dataset1_selected, df_dataset2_selected], ignore_index=True)\n",
    "\n",
    "# 6. Acak dataset gabungan untuk memastikan data tercampur dengan baik\n",
    "df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 7. Simpan dataset gabungan ke file CSV\n",
    "df_combined.to_csv('berita_combined.csv', index=False)\n",
    "\n",
    "# 8. Tampilkan informasi dataset\n",
    "print(f\"Dataset 1 (berita_terdahulu_grouping):\")\n",
    "print(f\"  - Data asli: {len(df_dataset1)}\")\n",
    "print(f\"  - Setelah cleaning: {len(df_dataset1_selected)}\")\n",
    "\n",
    "print(f\"\\nDataset 2 (berita_terkini_dengan_label):\")\n",
    "print(f\"  - Data asli: {len(df_dataset2)}\")\n",
    "print(f\"  - Setelah cleaning: {len(df_dataset2_selected)}\")\n",
    "\n",
    "print(f\"\\nDataset gabungan:\")\n",
    "print(f\"  - Total data: {len(df_combined)}\")\n",
    "\n",
    "print(f\"\\nKolom-kolom dalam dataset gabungan:\")\n",
    "print(df_combined.columns.tolist())\n",
    "\n",
    "print(f\"\\nInfo dataset gabungan:\")\n",
    "print(df_combined.info())\n",
    "\n",
    "print(f\"\\nContoh 5 baris pertama dari dataset gabungan:\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4faabcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALISIS DISTRIBUSI LABEL ===\n",
      "\n",
      "Dataset Gabungan - Distribusi Label:\n",
      "negatif    1542\n",
      "positif     748\n",
      "Name: label, dtype: int64\n",
      "Total data: 2290\n",
      "\n",
      "Dataset Gabungan - Persentase Label:\n",
      "  negatif: 1542 data (67.34%)\n",
      "  positif: 748 data (32.66%)\n",
      "\n",
      "Jumlah data dengan label kosong: 0\n",
      "\n",
      "Label unik yang tersedia:\n",
      "  - negatif\n",
      "  - positif\n",
      "\n",
      "Visualisasi Distribusi:\n",
      " negatif: ██████████████████████████████████████████████████ (1542)\n",
      " positif: ████████████████████████ (748)\n"
     ]
    }
   ],
   "source": [
    "# Analisis distribusi label dari dataset gabungan\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset gabungan yang sudah dibuat\n",
    "df_combined = pd.read_csv('berita_combined.csv')\n",
    "\n",
    "print(\"=== ANALISIS DISTRIBUSI LABEL ===\")\n",
    "\n",
    "# 1. Distribusi label secara keseluruhan\n",
    "print(f\"\\nDataset Gabungan - Distribusi Label:\")\n",
    "label_dist = df_combined['label'].value_counts().sort_index()\n",
    "print(label_dist)\n",
    "print(f\"Total data: {label_dist.sum()}\")\n",
    "\n",
    "# 2. Persentase distribusi label\n",
    "print(f\"\\nDataset Gabungan - Persentase Label:\")\n",
    "label_percentage = df_combined['label'].value_counts(normalize=True).sort_index() * 100\n",
    "for label, percentage in label_percentage.items():\n",
    "    count = label_dist[label]\n",
    "    print(f\"  {label}: {count} data ({percentage:.2f}%)\")\n",
    "\n",
    "# 3. Cek apakah ada nilai null di kolom label\n",
    "null_labels = df_combined['label'].isnull().sum()\n",
    "print(f\"\\nJumlah data dengan label kosong: {null_labels}\")\n",
    "\n",
    "# 4. Unique labels yang ada\n",
    "print(f\"\\nLabel unik yang tersedia:\")\n",
    "unique_labels = df_combined['label'].unique()\n",
    "for label in sorted(unique_labels):\n",
    "    if pd.notna(label):  # Skip jika ada NaN\n",
    "        print(f\"  - {label}\")\n",
    "\n",
    "# 5. Visualisasi sederhana\n",
    "print(f\"\\nVisualisasi Distribusi:\")\n",
    "max_count = label_dist.max()\n",
    "for label in sorted(label_dist.index):\n",
    "    count = label_dist[label]\n",
    "    bar_length = int((count / max_count) * 50)  # Scale to 50 characters max\n",
    "    bar = \"█\" * bar_length\n",
    "    print(f\"{label:>8}: {bar} ({count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f560d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membuat backup kolom date asli...\n",
      "=== TEST FORMAT INDONESIA ===\n",
      "Test konversi format Indonesia:\n",
      "  Jumat, 20 Des 2024 17:01 WIB → 20/12/2024\n",
      "  Rabu, 26 Jun 2024 19:17 WIB → 26/06/2024\n",
      "  Senin, 13 Mei 2024 19:57 WIB → 13/05/2024\n",
      "\n",
      "=== MELAKUKAN KONVERSI DENGAN DUKUNGAN FORMAT INDONESIA ===\n",
      "Mengkonversi ke format dd/mm/yyyy...\n",
      "\n",
      "=== HASIL KONVERSI ===\n",
      "Sample tanggal setelah konversi:\n",
      " 1. 15/03/2023\n",
      " 2. 15/03/2023\n",
      " 3. 30/08/2024\n",
      " 4. 02/05/2023\n",
      " 5. 27/03/2023\n",
      " 6. 06/07/2024\n",
      " 7. 28/03/2023\n",
      " 8. 21/03/2023\n",
      " 9. 06/04/2023\n",
      "10. 10/12/2022\n",
      "11. 21/11/2024\n",
      "12. 09/01/2024\n",
      "13. 20/12/2024\n",
      "14. 17/11/2023\n",
      "15. 07/12/2023\n",
      "\n",
      "Total data dengan tanggal setelah konversi: 2288\n",
      "Total data tanpa tanggal setelah konversi: 2\n",
      "\n",
      "Tingkat keberhasilan konversi: 100.0% (2288/2288)\n",
      "\n",
      "✅ Semua tanggal berhasil dikonversi ke format dd/mm/yyyy\n",
      "\n",
      "✅ Dataset dengan tanggal terstandarisasi disimpan ke: 'berita_combined_standardized_date.csv'\n",
      "\n",
      "=== SAMPLE PERBANDINGAN SEBELUM DAN SESUDAH ===\n",
      "✅ 2023-03-15 00:32:32+00                      → 15/03/2023\n",
      "✅ 2023-03-15 23:00:00+00                      → 15/03/2023\n",
      "✅ Jumat, 30 Agu 2024 22:04 WIB                → 30/08/2024\n",
      "✅ Selasa, 02 Mei  2023 16:35 WIB              → 02/05/2023\n",
      "✅ 2023-03-27 04:43:38+00                      → 27/03/2023\n",
      "✅ Sabtu, 06 Jul 2024 18:01 WIB                → 06/07/2024\n",
      "✅ 2023-03-28 15:30:52+00                      → 28/03/2023\n",
      "✅ 2023-03-21 09:38:13+00                      → 21/03/2023\n",
      "✅ 2023-04-06 20:00:27+00                      → 06/04/2023\n",
      "✅ 10/12/2022 16:15                            → 10/12/2022\n",
      "✅ Kamis, 21 Nov 2024 13:10 WIB                → 21/11/2024\n",
      "✅ 9/1/2024 12:30                              → 09/01/2024\n",
      "✅ 12/20/2024 15:05                            → 20/12/2024\n",
      "✅ 11/17/2023 19:40                            → 17/11/2023\n",
      "✅ 7/12/2023 11:45                             → 07/12/2023\n",
      "✅ Jumat, 03 Jan 2025 13:30 WIB                → 03/01/2025\n",
      "✅ 2023-04-08 08:18:17+00                      → 08/04/2023\n",
      "✅ 2023-03-14 09:37:29+00                      → 14/03/2023\n",
      "✅ 21/08/2024                                  → 21/08/2024\n",
      "✅ 10/16/2024 14:17                            → 16/10/2024\n",
      "\n",
      "=== FORMAT INDONESIA YANG DIDUKUNG ===\n",
      "Bulan yang dapat dikonversi:\n",
      "  jan, januari, feb, februari, mar, maret\n",
      "  apr, april, mei, may, jun, juni\n",
      "  jul, juli, agu, agustus, sep, september\n",
      "  okt, oktober, nov, november, des, desember\n",
      "\n",
      "Contoh format yang didukung:\n",
      "  - Jumat, 20 Des 2024 17:01 WIB\n",
      "  - Senin, 15 Jan 2024 10:30\n",
      "  - Rabu, 05 Februari 2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Load dataset gabungan\n",
    "df = pd.read_csv(r'D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\berita_combined.csv')\n",
    "\n",
    "# Mapping nama bulan Indonesia ke angka\n",
    "BULAN_INDONESIA = {\n",
    "    'jan': 1, 'januari': 1,\n",
    "    'feb': 2, 'februari': 2,\n",
    "    'mar': 3, 'maret': 3,\n",
    "    'apr': 4, 'april': 4,\n",
    "    'mei': 5, 'may': 5,\n",
    "    'jun': 6, 'juni': 6,\n",
    "    'jul': 7, 'juli': 7,\n",
    "    'agu': 8, 'agustus': 8,\n",
    "    'sep': 9, 'september': 9,\n",
    "    'okt': 10, 'oktober': 10,\n",
    "    'nov': 11, 'november': 11,\n",
    "    'des': 12, 'desember': 12\n",
    "}\n",
    "\n",
    "# Mapping nama hari Indonesia (opsional, untuk validasi)\n",
    "HARI_INDONESIA = {\n",
    "    'senin': 'monday',\n",
    "    'selasa': 'tuesday', \n",
    "    'rabu': 'wednesday',\n",
    "    'kamis': 'thursday',\n",
    "    'jumat': 'friday',\n",
    "    'sabtu': 'saturday',\n",
    "    'minggu': 'sunday'\n",
    "}\n",
    "\n",
    "def standardize_date_complete(date_str):\n",
    "    \"\"\"\n",
    "    Mengkonversi berbagai format tanggal termasuk format Indonesia menjadi dd/mm/yyyy\n",
    "    \"\"\"\n",
    "    if pd.isna(date_str) or date_str == '':\n",
    "        return None\n",
    "    \n",
    "    # Convert to string dan bersihkan\n",
    "    date_str = str(date_str).strip()\n",
    "    original_date_str = date_str\n",
    "    \n",
    "    # Hapus timezone indicator dan WIB\n",
    "    date_str = re.sub(r'\\+\\d{2}$', '', date_str)\n",
    "    date_str = re.sub(r'UTC$', '', date_str)\n",
    "    date_str = re.sub(r'WIB$', '', date_str)\n",
    "    date_str = date_str.strip()\n",
    "    \n",
    "    # Penanganan khusus untuk format Indonesia: \"Jumat, 20 Des 2024 17:01\"\n",
    "    indonesia_pattern = r'^(\\w+),?\\s+(\\d{1,2})\\s+(\\w+)\\s+(\\d{4})(?:\\s+\\d{1,2}:\\d{1,2}(?::\\d{1,2})?)?$'\n",
    "    indonesia_match = re.match(indonesia_pattern, date_str)\n",
    "    \n",
    "    if indonesia_match:\n",
    "        try:\n",
    "            hari, tanggal, bulan_str, tahun = indonesia_match.groups()\n",
    "            bulan_str = bulan_str.lower()\n",
    "            \n",
    "            if bulan_str in BULAN_INDONESIA:\n",
    "                bulan = BULAN_INDONESIA[bulan_str]\n",
    "                parsed_date = datetime(int(tahun), bulan, int(tanggal))\n",
    "                return parsed_date.strftime('%d/%m/%Y')\n",
    "        except ValueError as e:\n",
    "            print(f\"Error parsing Indonesian date '{original_date_str}': {e}\")\n",
    "    \n",
    "    # List format tanggal standar\n",
    "    date_formats = [\n",
    "        # Format dengan timezone sudah dihapus\n",
    "        '%Y-%m-%d %H:%M:%S',    # 2023-03-13 09:18:44\n",
    "        '%Y-%m-%d %H:%M',       # 2023-03-13 09:18\n",
    "        '%Y-%m-%d',             # 2023-03-13\n",
    "        '%Y/%m/%d %H:%M:%S',    # 2023/03/13 09:18:44\n",
    "        '%Y/%m/%d %H:%M',       # 2023/03/13 09:18\n",
    "        '%Y/%m/%d',             # 2023/03/13\n",
    "        \n",
    "        # Format d/m/yyyy\n",
    "        '%d/%m/%Y %H:%M:%S',    # 13/03/2023 09:18:44\n",
    "        '%d/%m/%Y %H:%M',       # 13/03/2023 09:18\n",
    "        '%d/%m/%Y',             # 13/03/2023\n",
    "        '%d-%m-%Y %H:%M:%S',    # 13-03-2023 09:18:44\n",
    "        '%d-%m-%Y %H:%M',       # 13-03-2023 09:18\n",
    "        '%d-%m-%Y',             # 13-03-2023\n",
    "        \n",
    "        # Format m/d/yyyy (US format)\n",
    "        '%m/%d/%Y %H:%M:%S',    # 03/13/2023 09:18:44\n",
    "        '%m/%d/%Y %H:%M',       # 03/13/2023 09:18\n",
    "        '%m/%d/%Y',             # 03/13/2023\n",
    "        \n",
    "        # Format tanpa separator\n",
    "        '%Y%m%d',               # 20230313\n",
    "        \n",
    "        # Format dengan nama bulan Inggris\n",
    "        '%d-%b-%Y',             # 13-Mar-2023\n",
    "        '%d %B %Y',             # 13 March 2023\n",
    "        '%B %d, %Y',            # March 13, 2023\n",
    "        '%d %b %Y',             # 13 Mar 2023\n",
    "    ]\n",
    "    \n",
    "    # Coba parsing dengan berbagai format\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            parsed_date = datetime.strptime(date_str, fmt)\n",
    "            return parsed_date.strftime('%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Penanganan khusus untuk format dengan angka tanpa leading zero\n",
    "    patterns = [\n",
    "        # yyyy-m-d atau yyyy/m/d\n",
    "        (r'^(\\d{4})[-/](\\d{1,2})[-/](\\d{1,2})(?:\\s+\\d{1,2}:\\d{1,2}(?::\\d{1,2})?)?$', 'yyyy-mm-dd'),\n",
    "        # m/d/yyyy dengan atau tanpa waktu (US format)\n",
    "        (r'^(\\d{1,2})/(\\d{1,2})/(\\d{4})(?:\\s+\\d{1,2}:\\d{1,2}(?::\\d{1,2})?)?$', 'mm/dd/yyyy'),\n",
    "        # d-m-yyyy atau d/m/yyyy\n",
    "        (r'^(\\d{1,2})[-/](\\d{1,2})[-/](\\d{4})(?:\\s+\\d{1,2}:\\d{1,2}(?::\\d{1,2})?)?$', 'dd-mm-yyyy'),\n",
    "    ]\n",
    "    \n",
    "    for pattern, format_type in patterns:\n",
    "        match = re.match(pattern, date_str)\n",
    "        if match:\n",
    "            groups = match.groups()\n",
    "            try:\n",
    "                if format_type == 'yyyy-mm-dd':\n",
    "                    year, month, day = groups\n",
    "                elif format_type == 'mm/dd/yyyy':\n",
    "                    month, day, year = groups\n",
    "                else:  # dd-mm-yyyy\n",
    "                    day, month, year = groups\n",
    "                \n",
    "                # Validasi tanggal\n",
    "                parsed_date = datetime(int(year), int(month), int(day))\n",
    "                return parsed_date.strftime('%d/%m/%Y')\n",
    "            except ValueError:\n",
    "                # Jika gagal, mungkin format US (m/d/yyyy) salah interpretasi\n",
    "                if format_type == 'dd-mm-yyyy':\n",
    "                    try:\n",
    "                        # Coba sebagai US format (m/d/yyyy)\n",
    "                        month, day, year = groups\n",
    "                        parsed_date = datetime(int(year), int(month), int(day))\n",
    "                        return parsed_date.strftime('%d/%m/%Y')\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                continue\n",
    "    \n",
    "    # Jika semua gagal, return nilai asli\n",
    "    print(f\"Warning: Could not parse date '{original_date_str}', keeping original value\")\n",
    "    return original_date_str\n",
    "\n",
    "# Backup data asli jika belum ada\n",
    "if 'date_original' not in df.columns:\n",
    "    print(\"Membuat backup kolom date asli...\")\n",
    "    df['date_original'] = df['date'].copy()\n",
    "\n",
    "# Test beberapa contoh format Indonesia\n",
    "print(\"=== TEST FORMAT INDONESIA ===\")\n",
    "test_dates = [\n",
    "    \"Jumat, 20 Des 2024 17:01 WIB\",\n",
    "    \"Rabu, 26 Jun 2024 19:17 WIB\", \n",
    "    \"Senin, 13 Mei 2024 19:57 WIB\"\n",
    "]\n",
    "\n",
    "print(\"Test konversi format Indonesia:\")\n",
    "for test_date in test_dates:\n",
    "    result = standardize_date_complete(test_date)\n",
    "    print(f\"  {test_date} → {result}\")\n",
    "\n",
    "# Konversi format tanggal dengan fungsi lengkap\n",
    "print(\"\\n=== MELAKUKAN KONVERSI DENGAN DUKUNGAN FORMAT INDONESIA ===\")\n",
    "print(\"Mengkonversi ke format dd/mm/yyyy...\")\n",
    "\n",
    "df['date'] = df['date_original'].apply(standardize_date_complete)\n",
    "\n",
    "# Cek hasil konversi\n",
    "print(\"\\n=== HASIL KONVERSI ===\")\n",
    "print(\"Sample tanggal setelah konversi:\")\n",
    "sample_dates_new = df['date'].dropna().head(15).tolist()\n",
    "for i, date in enumerate(sample_dates_new, 1):\n",
    "    print(f\"{i:2d}. {date}\")\n",
    "\n",
    "# Validasi hasil konversi\n",
    "print(f\"\\nTotal data dengan tanggal setelah konversi: {df['date'].notna().sum()}\")\n",
    "print(f\"Total data tanpa tanggal setelah konversi: {df['date'].isna().sum()}\")\n",
    "\n",
    "# Cek apakah ada tanggal yang tidak terkonversi dengan benar\n",
    "non_standard_dates = []\n",
    "successfully_converted = 0\n",
    "\n",
    "for date in df['date'].dropna():\n",
    "    if re.match(r'^\\d{2}/\\d{2}/\\d{4}$', str(date)):\n",
    "        successfully_converted += 1\n",
    "    else:\n",
    "        non_standard_dates.append(date)\n",
    "\n",
    "# Hitung tingkat keberhasilan konversi\n",
    "total_dates = len(df['date'].dropna())\n",
    "success_rate = (successfully_converted / total_dates * 100) if total_dates > 0 else 0\n",
    "\n",
    "print(f\"\\nTingkat keberhasilan konversi: {success_rate:.1f}% ({successfully_converted}/{total_dates})\")\n",
    "\n",
    "if non_standard_dates:\n",
    "    print(f\"\\nPeringatan: {len(non_standard_dates)} tanggal masih tidak sesuai format dd/mm/yyyy:\")\n",
    "    # Ambil sample unik untuk analisis\n",
    "    unique_non_standard = list(set(non_standard_dates))[:10]\n",
    "    for date in unique_non_standard:\n",
    "        print(f\"  - {date}\")\n",
    "    if len(unique_non_standard) > 10:\n",
    "        print(f\"  ... dan {len(unique_non_standard) - 10} format lainnya\")\n",
    "else:\n",
    "    print(f\"\\n✅ Semua tanggal berhasil dikonversi ke format dd/mm/yyyy\")\n",
    "\n",
    "# Simpan dataset dengan tanggal yang sudah distandarisasi\n",
    "df.to_csv('berita_combined_standardized_date.csv', index=False)\n",
    "print(f\"\\n✅ Dataset dengan tanggal terstandarisasi disimpan ke: 'berita_combined_standardized_date.csv'\")\n",
    "\n",
    "# Tampilkan contoh perbandingan\n",
    "print(f\"\\n=== SAMPLE PERBANDINGAN SEBELUM DAN SESUDAH ===\")\n",
    "comparison_sample = df[['date_original', 'date']].head(20)\n",
    "for idx, row in comparison_sample.iterrows():\n",
    "    original = str(row['date_original'])\n",
    "    converted = str(row['date'])\n",
    "    status = \"✅\" if re.match(r'^\\d{2}/\\d{2}/\\d{4}$', converted) else \"❌\"\n",
    "    # Potong teks jika terlalu panjang\n",
    "    original_short = original[:40] + \"...\" if len(original) > 40 else original\n",
    "    converted_short = converted[:40] + \"...\" if len(converted) > 40 else converted\n",
    "    print(f\"{status} {original_short:<43} → {converted_short}\")\n",
    "\n",
    "# Analisis format bermasalah yang tersisa\n",
    "if non_standard_dates:\n",
    "    print(f\"\\n=== ANALISIS FORMAT YANG MASIH BERMASALAH ===\")\n",
    "    problem_categories = {\n",
    "        'Format Indonesia belum tertangani': 0,\n",
    "        'Format dengan timezone kompleks': 0,\n",
    "        'Format ambiguous': 0,\n",
    "        'Format tidak dikenal': 0\n",
    "    }\n",
    "    \n",
    "    sample_problems = unique_non_standard[:20]  # Ambil sample untuk analisis\n",
    "    for date_str in sample_problems:\n",
    "        date_str = str(date_str)\n",
    "        if any(bulan in date_str.lower() for bulan in BULAN_INDONESIA.keys()):\n",
    "            problem_categories['Format Indonesia belum tertangani'] += 1\n",
    "        elif '+' in date_str or 'GMT' in date_str or 'UTC' in date_str:\n",
    "            problem_categories['Format dengan timezone kompleks'] += 1\n",
    "        elif '/' in date_str and len(date_str.split('/')) == 3:\n",
    "            problem_categories['Format ambiguous'] += 1\n",
    "        else:\n",
    "            problem_categories['Format tidak dikenal'] += 1\n",
    "    \n",
    "    print(\"Kategori masalah yang tersisa:\")\n",
    "    for category, count in problem_categories.items():\n",
    "        if count > 0:\n",
    "            print(f\"  - {category}: {count} kasus\")\n",
    "            \n",
    "# Informasi tambahan tentang bulan Indonesia yang didukung\n",
    "print(f\"\\n=== FORMAT INDONESIA YANG DIDUKUNG ===\")\n",
    "print(\"Bulan yang dapat dikonversi:\")\n",
    "bulan_list = list(BULAN_INDONESIA.keys())\n",
    "for i in range(0, len(bulan_list), 6):\n",
    "    print(f\"  {', '.join(bulan_list[i:i+6])}\")\n",
    "\n",
    "print(f\"\\nContoh format yang didukung:\")\n",
    "print(f\"  - Jumat, 20 Des 2024 17:01 WIB\")\n",
    "print(f\"  - Senin, 15 Jan 2024 10:30\")\n",
    "print(f\"  - Rabu, 05 Februari 2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58890f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SORTING DATA BERDASARKAN TANGGAL (2020-2024) ===\n",
      "Total data awal: 2290\n",
      "Mengkonversi tanggal ke format datetime...\n",
      "Berhasil mengkonversi 2288 dari 2290 tanggal ke datetime\n",
      "\n",
      "Memfilter data untuk tahun 2020-2024...\n",
      "Data setelah filter tahun 2020-2024: 2279\n",
      "\n",
      "=== DISTRIBUSI DATA PER TAHUN ===\n",
      "  2020: 29 data\n",
      "  2021: 19 data\n",
      "  2022: 68 data\n",
      "  2023: 970 data\n",
      "  2024: 1193 data\n",
      "\n",
      "Mengurutkan data dari tanggal terbaru ke lama...\n",
      "\n",
      "=== HASIL SORTING ===\n",
      "Total data final: 2279\n",
      "\n",
      "10 Data Terbaru:\n",
      "   1. [31/12/2024] Prabowo Ungkap Alasan Umumkan Sendiri Kenaikan PPN...\n",
      "   2. [31/12/2024] Harga BBM di Tahun 2025 Bakal Turun? Begini Perkir...\n",
      "   3. [31/12/2024] Geger Jutaan Masyarakat Kelas Menengah RI Turun Ka...\n",
      "   4. [31/12/2024] Drama Rupiah: Ketika Jokowi Ketar-ketir Gegara Dol...\n",
      "   5. [31/12/2024] Respons Maman soal Dampak Kebijakan Proteksionisme...\n",
      "   6. [31/12/2024] 10 Negara dengan Harga Rumah Paling Mahal di Dunia...\n",
      "   7. [31/12/2024] Waka DPR sebut Kenaikan PPN 12% Amanat UU, Tak Aka...\n",
      "   8. [30/12/2024] IMF Puji Pertumbuhan Ekonomi RI & PDB Tembus Rp 22...\n",
      "   9. [30/12/2024] Harga BBM di 2025 Bakal Turun? Begini Prediksinya\n",
      "  10. [30/12/2024] Meneropong Tantangan Ekonomi RI di 2025\n",
      "\n",
      "10 Data Terlama:\n",
      "  2270. [8/7/2020] Cadev RI Cetak Rekor, Rupiah Kok Tetap Melempem?\n",
      "  2271. [8/6/2020] Rupiah Start Apik, eh...Malah Finis Paling Buncit\n",
      "  2272. [8/5/2020] Gerbang Resesi RI Akan Terbuka, Apa Kabar IHSG Har...\n",
      "  2273. [8/4/2020] Bangkit di Menit-menit Akhir, Rupiah Catat Penguat...\n",
      "  2274. [8/4/2020] Duh! Rupiah Terancam Di-Hattrick Dolar AS Nih\n",
      "  2275. [7/1/2020] Reli Saat Injury Time, IHSG Berhasil Ditutup Naik ...\n",
      "  2276. [7/1/2020] Reli Wall Street Berlanjut, IHSG Berpeluang Hijau ...\n",
      "  2277. [7/1/2020] Asing Masih Kabur, IHSG Dibuka Hijau tapi Malu-mal...\n",
      "  2278. [22/06/2020] Sikat 2 Tambang Asing & Aksi Hebat Bin Mantap Joko...\n",
      "  2279. [17/04/2020] S&P Pangkas Proyeksi Pertumbuhan 2020 RI ke 1,8%\n",
      "\n",
      "Rentang waktu data:\n",
      "  Terbaru: 31/12/2024 (Tuesday, 31 December 2024)\n",
      "  Terlama: 17/04/2020 (Friday, 17 April 2020)\n",
      "\n",
      "=== DISTRIBUSI BULAN TAHUN 2024 ===\n",
      "  Jan 2024: 79 data\n",
      "  Feb 2024: 45 data\n",
      "  Mar 2024: 89 data\n",
      "  Apr 2024: 153 data\n",
      "  Mei 2024: 76 data\n",
      "  Jun 2024: 190 data\n",
      "  Jul 2024: 116 data\n",
      "  Agu 2024: 150 data\n",
      "  Sep 2024: 48 data\n",
      "  Okt 2024: 84 data\n",
      "  Nov 2024: 84 data\n",
      "  Des 2024: 79 data\n",
      "\n",
      "✅ Data yang sudah diurutkan berdasarkan tanggal disimpan ke: 'berita_sorted_2020_2024.csv'\n",
      "\n",
      "=== VALIDASI AKHIR ===\n",
      "✅ Data diurutkan dari: 2024 hingga 2020\n",
      "✅ Total data: 2279\n",
      "✅ Kolom yang tersimpan: ['Title', 'Content', 'stemmed_text', 'faktor_str', 'label', 'date']\n",
      "⚠️  Terdeteksi 35 data duplikat berdasarkan content\n",
      "   Jika ingin menghapus duplikat, jalankan: df_final.drop_duplicates(subset=['Content'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Load dataset yang sudah distandarisasi tanggalnya\n",
    "df = pd.read_csv(r'D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\berita_combined_standardized_date.csv')\n",
    "\n",
    "print(f\"=== SORTING DATA BERDASARKAN TANGGAL (2020-2024) ===\")\n",
    "print(f\"Total data awal: {len(df)}\")\n",
    "\n",
    "# Fungsi untuk convert tanggal dd/mm/yyyy ke datetime\n",
    "def parse_date_to_datetime(date_str):\n",
    "    \"\"\"\n",
    "    Convert format dd/mm/yyyy ke datetime object\n",
    "    \"\"\"\n",
    "    if pd.isna(date_str) or date_str == '':\n",
    "        return None\n",
    "    \n",
    "    date_str = str(date_str).strip()\n",
    "    \n",
    "    # Cek apakah sudah format dd/mm/yyyy\n",
    "    if re.match(r'^\\d{2}/\\d{2}/\\d{4}$', date_str):\n",
    "        try:\n",
    "            return datetime.strptime(date_str, '%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            return None\n",
    "    \n",
    "    # Jika belum format standar, coba parse format lain\n",
    "    formats_to_try = [\n",
    "        '%Y-%m-%d',           # 2024-01-15\n",
    "        '%Y/%m/%d',           # 2024/01/15\n",
    "        '%d-%m-%Y',           # 15-01-2024\n",
    "        '%m/%d/%Y',           # 01/15/2024\n",
    "        '%Y-%m-%d %H:%M:%S',  # 2024-01-15 10:30:45\n",
    "        '%d/%m/%Y %H:%M:%S',  # 15/01/2024 10:30:45\n",
    "    ]\n",
    "    \n",
    "    for fmt in formats_to_try:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Convert kolom date ke datetime\n",
    "print(\"Mengkonversi tanggal ke format datetime...\")\n",
    "df['date_datetime'] = df['date'].apply(parse_date_to_datetime)\n",
    "\n",
    "# Cek berapa yang berhasil dikonversi\n",
    "converted_count = df['date_datetime'].notna().sum()\n",
    "print(f\"Berhasil mengkonversi {converted_count} dari {len(df)} tanggal ke datetime\")\n",
    "\n",
    "# Filter data untuk tahun 2020-2024\n",
    "print(\"\\nMemfilter data untuk tahun 2020-2024...\")\n",
    "df_with_date = df[df['date_datetime'].notna()].copy()\n",
    "\n",
    "# Filter berdasarkan tahun\n",
    "df_filtered = df_with_date[\n",
    "    (df_with_date['date_datetime'].dt.year >= 2020) & \n",
    "    (df_with_date['date_datetime'].dt.year <= 2024)\n",
    "].copy()\n",
    "\n",
    "print(f\"Data setelah filter tahun 2020-2024: {len(df_filtered)}\")\n",
    "\n",
    "# Analisis distribusi per tahun sebelum sorting\n",
    "print(f\"\\n=== DISTRIBUSI DATA PER TAHUN ===\")\n",
    "year_distribution = df_filtered['date_datetime'].dt.year.value_counts().sort_index()\n",
    "for year, count in year_distribution.items():\n",
    "    print(f\"  {year}: {count} data\")\n",
    "\n",
    "# Sort berdasarkan tanggal dari terbaru ke lama (descending)\n",
    "print(f\"\\nMengurutkan data dari tanggal terbaru ke lama...\")\n",
    "df_sorted = df_filtered.sort_values('date_datetime', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Hapus kolom helper datetime jika tidak diperlukan\n",
    "df_final = df_sorted.drop('date_datetime', axis=1)\n",
    "\n",
    "print(f\"\\n=== HASIL SORTING ===\")\n",
    "print(f\"Total data final: {len(df_final)}\")\n",
    "\n",
    "# Tampilkan sample 10 data teratas (terbaru)\n",
    "print(f\"\\n10 Data Terbaru:\")\n",
    "sample_newest = df_final[['Title', 'date']].head(10)\n",
    "for idx, row in sample_newest.iterrows():\n",
    "    title_short = str(row['Title'])[:50] + \"...\" if len(str(row['Title'])) > 50 else str(row['Title'])\n",
    "    print(f\"  {idx+1:2d}. [{row['date']}] {title_short}\")\n",
    "\n",
    "# Tampilkan sample 10 data terlama\n",
    "print(f\"\\n10 Data Terlama:\")\n",
    "sample_oldest = df_final[['Title', 'date']].tail(10)\n",
    "for idx, row in sample_oldest.iterrows():\n",
    "    title_short = str(row['Title'])[:50] + \"...\" if len(str(row['Title'])) > 50 else str(row['Title'])\n",
    "    relative_idx = len(df_final) - (len(df_final) - idx - 1)\n",
    "    print(f\"  {relative_idx:2d}. [{row['date']}] {title_short}\")\n",
    "\n",
    "# Cek tanggal terbaru dan terlama\n",
    "if len(df_sorted) > 0:\n",
    "    newest_date = df_sorted['date_datetime'].iloc[0]\n",
    "    oldest_date = df_sorted['date_datetime'].iloc[-1]\n",
    "    print(f\"\\nRentang waktu data:\")\n",
    "    print(f\"  Terbaru: {newest_date.strftime('%d/%m/%Y')} ({newest_date.strftime('%A, %d %B %Y')})\")\n",
    "    print(f\"  Terlama: {oldest_date.strftime('%d/%m/%Y')} ({oldest_date.strftime('%A, %d %B %Y')})\")\n",
    "\n",
    "# Analisis distribusi per bulan tahun terbaru\n",
    "if len(df_sorted) > 0:\n",
    "    latest_year = df_sorted['date_datetime'].iloc[0].year\n",
    "    print(f\"\\n=== DISTRIBUSI BULAN TAHUN {latest_year} ===\")\n",
    "    latest_year_data = df_sorted[df_sorted['date_datetime'].dt.year == latest_year]\n",
    "    if len(latest_year_data) > 0:\n",
    "        month_dist = latest_year_data['date_datetime'].dt.month.value_counts().sort_index()\n",
    "        month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'Mei', 'Jun', \n",
    "                      'Jul', 'Agu', 'Sep', 'Okt', 'Nov', 'Des']\n",
    "        for month, count in month_dist.items():\n",
    "            print(f\"  {month_names[month-1]} {latest_year}: {count} data\")\n",
    "\n",
    "# Simpan data yang sudah diurutkan\n",
    "output_filename = 'berita_sorted_2020_2024.csv'\n",
    "df_final.to_csv(output_filename, index=False)\n",
    "print(f\"\\n✅ Data yang sudah diurutkan berdasarkan tanggal disimpan ke: '{output_filename}'\")\n",
    "\n",
    "# Validasi akhir\n",
    "print(f\"\\n=== VALIDASI AKHIR ===\")\n",
    "print(f\"✅ Data diurutkan dari: {year_distribution.index.max()} hingga {year_distribution.index.min()}\")\n",
    "print(f\"✅ Total data: {len(df_final)}\")\n",
    "print(f\"✅ Kolom yang tersimpan: {list(df_final.columns)}\")\n",
    "\n",
    "# Cek apakah ada duplikat berdasarkan content\n",
    "duplicates = df_final.duplicated(subset=['Content']).sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"⚠️  Terdeteksi {duplicates} data duplikat berdasarkan content\")\n",
    "    print(f\"   Jika ingin menghapus duplikat, jalankan: df_final.drop_duplicates(subset=['Content'], inplace=True)\")\n",
    "else:\n",
    "    print(f\"✅ Tidak ada duplikat berdasarkan content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b688364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop_duplicates(subset=['Content'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513a7a6",
   "metadata": {},
   "source": [
    "## WORD EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d098a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a1ce8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d100d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>faktor_str</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prabowo Ungkap Alasan Umumkan Sendiri Kenaikan...</td>\n",
       "      <td>Presiden Prabowo Subianto mengumumkan kenaikan...</td>\n",
       "      <td>presiden prabowo subianto umum naik tarif ppn ...</td>\n",
       "      <td>['suku_bunga', 'ekspor']</td>\n",
       "      <td>negatif</td>\n",
       "      <td>31/12/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harga BBM di Tahun 2025 Bakal Turun? Begini Pe...</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Direktur Center of E...</td>\n",
       "      <td>jakarta cnbc indonesia direktur center of econ...</td>\n",
       "      <td>['suku_bunga']</td>\n",
       "      <td>positif</td>\n",
       "      <td>31/12/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geger Jutaan Masyarakat Kelas Menengah RI Turu...</td>\n",
       "      <td>Jumlah kelas menengah di Indonesia terus menga...</td>\n",
       "      <td>kelas tengah indonesia alami turun dasar data ...</td>\n",
       "      <td>['suku_bunga', 'ekspor']</td>\n",
       "      <td>negatif</td>\n",
       "      <td>31/12/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drama Rupiah: Ketika Jokowi Ketar-ketir Gegara...</td>\n",
       "      <td>Nilai tukar dolar Amerika Serikat (AS) menunju...</td>\n",
       "      <td>nilai tukar dolar amerika serikat as dominasi ...</td>\n",
       "      <td>['suku_bunga', 'impor', 'ekspor']</td>\n",
       "      <td>negatif</td>\n",
       "      <td>31/12/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Respons Maman soal Dampak Kebijakan Proteksion...</td>\n",
       "      <td>Menteri Usaha Mikro, Kecil, dan Menengah (UMKM...</td>\n",
       "      <td>menteri usaha mikro tengah umkm maman abdurrah...</td>\n",
       "      <td>['suku_bunga', 'impor', 'ekspor']</td>\n",
       "      <td>negatif</td>\n",
       "      <td>31/12/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>Reli Saat Injury Time, IHSG Berhasil Ditutup N...</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Indeks Harga Saham G...</td>\n",
       "      <td>jakarta cnbc indonesia indeks harga saham gabu...</td>\n",
       "      <td>['suku_bunga']</td>\n",
       "      <td>positif</td>\n",
       "      <td>7/1/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>Reli Wall Street Berlanjut, IHSG Berpeluang Hi...</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Kinerja Indeks Harga...</td>\n",
       "      <td>jakarta cnbc indonesia kerja indeks harga saha...</td>\n",
       "      <td>['suku_bunga']</td>\n",
       "      <td>positif</td>\n",
       "      <td>7/1/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>Asing Masih Kabur, IHSG Dibuka Hijau tapi Malu...</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Indeks Harga Saham G...</td>\n",
       "      <td>jakarta cnbc indonesia indeks harga saham gabu...</td>\n",
       "      <td>['suku_bunga']</td>\n",
       "      <td>positif</td>\n",
       "      <td>7/1/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>Sikat 2 Tambang Asing &amp; Aksi Hebat Bin Mantap ...</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Presiden Joko Widodo...</td>\n",
       "      <td>jakarta cnbc indonesia presiden joko widodo jo...</td>\n",
       "      <td>['suku_bunga', 'ekspor']</td>\n",
       "      <td>positif</td>\n",
       "      <td>22/06/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>S&amp;P Pangkas Proyeksi Pertumbuhan 2020 RI ke 1,8%</td>\n",
       "      <td>Jakarta, CNBC Indonesia - S&amp;P Global Ratings m...</td>\n",
       "      <td>jakarta cnbc indonesia s p global ratings proy...</td>\n",
       "      <td>['suku_bunga']</td>\n",
       "      <td>positif</td>\n",
       "      <td>17/04/2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2279 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Prabowo Ungkap Alasan Umumkan Sendiri Kenaikan...   \n",
       "1     Harga BBM di Tahun 2025 Bakal Turun? Begini Pe...   \n",
       "2     Geger Jutaan Masyarakat Kelas Menengah RI Turu...   \n",
       "3     Drama Rupiah: Ketika Jokowi Ketar-ketir Gegara...   \n",
       "4     Respons Maman soal Dampak Kebijakan Proteksion...   \n",
       "...                                                 ...   \n",
       "2274  Reli Saat Injury Time, IHSG Berhasil Ditutup N...   \n",
       "2275  Reli Wall Street Berlanjut, IHSG Berpeluang Hi...   \n",
       "2276  Asing Masih Kabur, IHSG Dibuka Hijau tapi Malu...   \n",
       "2277  Sikat 2 Tambang Asing & Aksi Hebat Bin Mantap ...   \n",
       "2278   S&P Pangkas Proyeksi Pertumbuhan 2020 RI ke 1,8%   \n",
       "\n",
       "                                                Content  \\\n",
       "0     Presiden Prabowo Subianto mengumumkan kenaikan...   \n",
       "1     Jakarta, CNBC Indonesia - Direktur Center of E...   \n",
       "2     Jumlah kelas menengah di Indonesia terus menga...   \n",
       "3     Nilai tukar dolar Amerika Serikat (AS) menunju...   \n",
       "4     Menteri Usaha Mikro, Kecil, dan Menengah (UMKM...   \n",
       "...                                                 ...   \n",
       "2274  Jakarta, CNBC Indonesia - Indeks Harga Saham G...   \n",
       "2275  Jakarta, CNBC Indonesia - Kinerja Indeks Harga...   \n",
       "2276  Jakarta, CNBC Indonesia - Indeks Harga Saham G...   \n",
       "2277  Jakarta, CNBC Indonesia - Presiden Joko Widodo...   \n",
       "2278  Jakarta, CNBC Indonesia - S&P Global Ratings m...   \n",
       "\n",
       "                                           stemmed_text  \\\n",
       "0     presiden prabowo subianto umum naik tarif ppn ...   \n",
       "1     jakarta cnbc indonesia direktur center of econ...   \n",
       "2     kelas tengah indonesia alami turun dasar data ...   \n",
       "3     nilai tukar dolar amerika serikat as dominasi ...   \n",
       "4     menteri usaha mikro tengah umkm maman abdurrah...   \n",
       "...                                                 ...   \n",
       "2274  jakarta cnbc indonesia indeks harga saham gabu...   \n",
       "2275  jakarta cnbc indonesia kerja indeks harga saha...   \n",
       "2276  jakarta cnbc indonesia indeks harga saham gabu...   \n",
       "2277  jakarta cnbc indonesia presiden joko widodo jo...   \n",
       "2278  jakarta cnbc indonesia s p global ratings proy...   \n",
       "\n",
       "                             faktor_str    label        date  \n",
       "0              ['suku_bunga', 'ekspor']  negatif  31/12/2024  \n",
       "1                        ['suku_bunga']  positif  31/12/2024  \n",
       "2              ['suku_bunga', 'ekspor']  negatif  31/12/2024  \n",
       "3     ['suku_bunga', 'impor', 'ekspor']  negatif  31/12/2024  \n",
       "4     ['suku_bunga', 'impor', 'ekspor']  negatif  31/12/2024  \n",
       "...                                 ...      ...         ...  \n",
       "2274                     ['suku_bunga']  positif    7/1/2020  \n",
       "2275                     ['suku_bunga']  positif    7/1/2020  \n",
       "2276                     ['suku_bunga']  positif    7/1/2020  \n",
       "2277           ['suku_bunga', 'ekspor']  positif  22/06/2020  \n",
       "2278                     ['suku_bunga']  positif  17/04/2020  \n",
       "\n",
       "[2279 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\berita_combined_2020-2024.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b8b3c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokumen 1: ['presiden', 'prabowo', 'subianto', 'umum', 'naik', 'tarif', 'ppn', 'belas', 'laku', 'barang']...\n",
      "Dokumen 2: ['jakarta', 'cnbc', 'indonesia', 'direktur', 'center', 'of', 'economic', 'and', 'law', 'studies']...\n",
      "Dokumen 3: ['kelas', 'tengah', 'indonesia', 'alami', 'turun', 'dasar', 'data', 'badan', 'pusat', 'statistik']...\n",
      "Dokumen 4: ['nilai', 'tukar', 'dolar', 'amerika', 'serikat', 'as', 'dominasi', 'rupiah', 'ribu', 'puluh']...\n",
      "Dokumen 5: ['menteri', 'usaha', 'mikro', 'tengah', 'umkm', 'maman', 'abdurrahman', 'sebut', 'sektor', 'ekspor']...\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.split()\n",
    "    return []\n",
    "tokenized_docs = [tokenize_text(text) for text in df['stemmed_text']]\n",
    "\n",
    "for i in range(min(5, len(tokenized_docs))):\n",
    "    print(f\"Dokumen {i+1}: {tokenized_docs[i][:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df177d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melatih model FastText\n",
    "vector_size = 100  # dimensi vektor\n",
    "window = 5         # ukuran jendela konteks\n",
    "min_count = 2      # frekuensi kata minimum\n",
    "workers = 4        # jumlah thread\n",
    "sg = 1             # Skip-gram (1) vs CBOW (0)\n",
    "epochs = 20        # jumlah epoch pelatihan\n",
    "\n",
    "# Latih model\n",
    "model_ft = FastText(\n",
    "    tokenized_docs,\n",
    "    vector_size=vector_size,\n",
    "    window=window,\n",
    "    min_count=min_count,\n",
    "    workers=workers,\n",
    "    sg=sg,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "107a41a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kata-kata yang serupa dengan kata kunci:\n",
      "\n",
      "Kata yang mirip dengan 'krisis':\n",
      "  delapankrisis: 0.7808\n",
      "  crisis: 0.7527\n",
      "  krismo: 0.7510\n",
      "  krismon: 0.7460\n",
      "  subprime: 0.6693\n",
      "\n",
      "Kata yang mirip dengan 'ekonomi':\n",
      "  ekonomis: 0.8021\n",
      "  geoekonomi: 0.7964\n",
      "  tumbuh: 0.7199\n",
      "  makroekonomi: 0.7026\n",
      "  indikatortingkatpertumbuhan: 0.6460\n",
      "\n",
      "Kata yang mirip dengan 'moneter':\n",
      "  nonmoneter: 0.7362\n",
      "  monetari: 0.6883\n",
      "  monetisasi: 0.6651\n",
      "  bijak: 0.6415\n",
      "  krismon: 0.6356\n",
      "\n",
      "Kata yang mirip dengan 'inflasi':\n",
      "  asinflasi: 0.8844\n",
      "  disinflasi: 0.7756\n",
      "  ihk: 0.7121\n",
      "  hiperinflasi: 0.7016\n",
      "  landai: 0.7011\n",
      "\n",
      "Kata yang mirip dengan 'ekspor':\n",
      "  eksportir: 0.7336\n",
      "  nonmigas: 0.6985\n",
      "  eksporpelemahan: 0.6648\n",
      "  ekspos: 0.6386\n",
      "  bauksit: 0.6317\n",
      "\n",
      "Kata yang mirip dengan 'impor':\n",
      "  imporhal: 0.7833\n",
      "  import: 0.7449\n",
      "  importasi: 0.7355\n",
      "  importer: 0.7323\n",
      "  importir: 0.6732\n",
      "\n",
      "Kata yang mirip dengan 'bunga':\n",
      "  suku: 0.9297\n",
      "  acu: 0.7491\n",
      "  mangkas: 0.6856\n",
      "  fedpada: 0.6854\n",
      "  agresif: 0.6854\n"
     ]
    }
   ],
   "source": [
    "# memeriksa hasil model\n",
    "kata_kunci = ['krisis', 'ekonomi', 'moneter', 'inflasi', 'ekspor', 'impor', 'bunga'] #periksa kata yang mirip\n",
    "print(\"\\nKata-kata yang serupa dengan kata kunci:\")\n",
    "for kata in kata_kunci:\n",
    "    try:\n",
    "        similar_words = model_ft.wv.most_similar(kata, topn=5)\n",
    "        print(f\"\\nKata yang mirip dengan '{kata}':\")\n",
    "        for word, similarity in similar_words:\n",
    "            print(f\"  {word}: {similarity:.4f}\")\n",
    "    except KeyError:\n",
    "        print(f\"\\n'{kata}' tidak ditemukan dalam kosakata model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33b71e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2279/2279 [00:21<00:00, 104.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bentuk vektor dokumen: (2279, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# konversi dokumen ke vektor\n",
    "def get_document_vector(doc_tokens, model):\n",
    "    \"\"\"Mengkonversi dokumen (list token) menjadi vektor dengan rata-rata vektor token\"\"\"\n",
    "    vec = np.zeros(model.vector_size)\n",
    "    count = 0\n",
    "    for token in doc_tokens:\n",
    "        try:\n",
    "            vec += model.wv[token]\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count > 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "# konversi dokumen ke vektor\n",
    "doc_vectors = []\n",
    "for doc in tqdm(tokenized_docs):\n",
    "    doc_vectors.append(get_document_vector(doc, model_ft))\n",
    "# mengubah ke array numpy\n",
    "doc_vectors = np.array(doc_vectors)\n",
    "print(f\"Bentuk vektor dokumen: {doc_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6260687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpan model dan vektor\n",
    "model_ft.save(\"model_fasttext_berita.bin\")\n",
    "with open(\"doc_vectors_fasttext_terbaru.pkl\", \"wb\") as f:\n",
    "    pickle.dump(doc_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24f9ae2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-8f24947bafa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtsne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mvectors_tsne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \"\"\"\n\u001b[0;32m   1110\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1111\u001b[1;33m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1112\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             \u001b[0mdistances_nn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"distance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m             \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[1;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"distance\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m             \u001b[0mA_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[0mA_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    820\u001b[0m         )\n\u001b[0;32m    821\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m             results = ArgKmin.compute(\n\u001b[0m\u001b[0;32m    823\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             return ArgKmin64.compute(\n\u001b[0m\u001b[0;32m    260\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36mthreadpool_limits\u001b[1;34m(limits, user_api)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreadpool_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, limits, user_api)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_threadpool_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_set_threadpool_limits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         modules = _ThreadpoolInfo(prefixes=self._prefixes,\n\u001b[0m\u001b[0;32m    269\u001b[0m                                   user_api=self._user_api)\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_modules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_if_incompatible_openmp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dyld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dl_iterate_phdr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                 \u001b[1;31m# Store the module if it is supported and selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_module_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mkernel_32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCloseHandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefixes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0muser_api\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[0mmodule_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_api\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynlib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_RTLD_NOLOAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_threads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_extra_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36mget_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    644\u001b[0m                              lambda: None)\n\u001b[0;32m    645\u001b[0m         \u001b[0mget_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"OpenBLAS\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# visualisasi dengan t-sne\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "label_map = {'positif': 1, 'negatif': 0} #split berdasarkan label sentimen\n",
    "y = df['label'].map(label_map).values\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "vectors_tsne = tsne.fit_transform(doc_vectors)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    vectors_tsne[:, 0], \n",
    "    vectors_tsne[:, 1], \n",
    "    c=y, \n",
    "    cmap='coolwarm', \n",
    "    alpha=0.7,\n",
    "    s=50\n",
    ")\n",
    "plt.colorbar(scatter, label='Label (1=positif, 0=negatif)')\n",
    "plt.title('Visualisasi t-SNE dari Vektor Dokumen FastText berdasarkan Sentimen', fontsize=12)\n",
    "plt.xlabel('Dimensi 1', fontsize=12)\n",
    "plt.ylabel('Dimensi 2', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a392c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
