{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1537d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # 1. Load kedua dataset\n",
    "# # Ganti path sesuai dengan lokasi file Anda\n",
    "# df_dataset2 = pd.read_csv(r'D:\\SKRIPSI\\skripsi_2025\\dataset berita terkini 2\\data_compressed.csv.gz', compression='gzip')\n",
    "# df_dataset3 = pd.read_csv(r'D:\\SKRIPSI\\skripsi_2025\\dataset berita terkini 3\\politik_merge_compressed.csv.gz', compression='gzip')\n",
    "\n",
    "# # 2. Sesuaikan nama kolom agar konsisten\n",
    "# # Berdasarkan dataset yang Anda upload, dataset2 memiliki kolom 'content' dan 'title'\n",
    "# # Sedangkan dataset3 memiliki kolom 'Content' dan 'Judul'\n",
    "# df_dataset3 = df_dataset3.rename(columns={'Content': 'content', 'Judul': 'title', 'Waktu': 'date'})\n",
    "\n",
    "# # 3. Pilih hanya kolom yang dibutuhkan\n",
    "# df_dataset2 = df_dataset2[['content', 'title', 'date']]\n",
    "# df_dataset3 = df_dataset3[['content', 'title', 'date']]\n",
    "\n",
    "# # # 4. Hapus duplikat dan nilai kosong dari kedua dataset\n",
    "# # df_dataset2 = df_dataset2.drop_duplicates(subset=['content'])\n",
    "# # df_dataset2 = df_dataset2.dropna(subset=['content', 'title'])\n",
    "\n",
    "# # df_dataset3 = df_dataset3.drop_duplicates(subset=['content'])\n",
    "# # df_dataset3 = df_dataset3.dropna(subset=['content', 'title'])\n",
    "\n",
    "# # 5. Ambil 3500 sampel dari masing-masing dataset\n",
    "# sample_size = 3000\n",
    "# df_sample2 = df_dataset2.sample(n=sample_size, random_state=42)\n",
    "# df_sample3 = df_dataset3.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# # 6. Gabungkan kedua sampel\n",
    "# df_combined = pd.concat([df_sample2, df_sample3], ignore_index=True)\n",
    "\n",
    "# # 7. Acak dataset gabungan untuk memastikan data tercampur dengan baik\n",
    "# df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # 8. Simpan dataset gabungan ke file CSV\n",
    "# df_combined.to_csv('berita_terkini.csv', index=False)\n",
    "\n",
    "# # 9. Tampilkan informasi dataset\n",
    "# print(f\"Jumlah data dari dataset2: {len(df_sample2)}\")\n",
    "# print(f\"Jumlah data dari dataset3: {len(df_sample3)}\")\n",
    "# print(f\"Jumlah data pada dataset gabungan: {len(df_combined)}\")\n",
    "# print(\"\\nContoh 5 baris data dari dataset gabungan:\")\n",
    "# df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df34035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from indonesian_number_normalizer import create_normalizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e50f029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "normalizer = create_normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1d21b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Presiden bertemu dengan timnas U-20 di GBK, Se...</td>\n",
       "      <td>Jokowi: Beberapa Pemain Timnas U-20 Ingin Kuli...</td>\n",
       "      <td>2023-04-01 10:36:35+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Presiden Joko Widodo (Jokowi) melakukan kunjun...</td>\n",
       "      <td>Kunker ke Lampung, Jokowi Akan Resmikan Bendun...</td>\n",
       "      <td>Senin, 26 Agu 2024 08:53 WIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Menteri Koordinator Politik, Hukum, dan Keaman...</td>\n",
       "      <td>Mahfud Buat Satgas Tindak Lanjuti Rp 349 T, Di...</td>\n",
       "      <td>2023-04-10 05:28:58+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JAKARTA - Cara tambah daya listrik hingga 5.50...</td>\n",
       "      <td>Tambah Daya Listrik hingga 5.500 VA dengan Bay...</td>\n",
       "      <td>2023-03-23 02:41:24+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sekretaris Jenderal PBNU Gus Saifullah Yusuf (...</td>\n",
       "      <td>Sekjen PBNU: Hubungan Santri dan Polri Baik, S...</td>\n",
       "      <td>Selasa, 03 Sep 2024 12:43 WIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>TEMPO.CO, Jakarta - Tim Pembela Prabowo-Gibran...</td>\n",
       "      <td>Hari Ini, Kubu Prabowo-Gibran Bakal Hadirkan 1...</td>\n",
       "      <td>4/4/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>Bakal calon Wakil Gubernur DKI Jakarta Rano Ka...</td>\n",
       "      <td>Rano Karno Ungkap Obrolan dengan Anies di Kant...</td>\n",
       "      <td>Rabu, 28 Agu 2024 12:16 WIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>Lembaga Survei Indonesia (LSI) mengungkapkan b...</td>\n",
       "      <td>Buah Kerja Keras Airin, Unggul di Semua Simula...</td>\n",
       "      <td>Kamis, 22 Agu 2024 11:45 WIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>JAKARTA, KOMPAS.com - Jaksa Penuntut Umum (JP...</td>\n",
       "      <td>Jaksa Bocorkan \"Chat\" Gazalba dengan Perempuan...</td>\n",
       "      <td>8/8/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>JAKARTA  Cara daftar mudik gratis Kemenhub, BU...</td>\n",
       "      <td>Cara Daftar Mudik Gratis Kemenhub, BUMN dan Ja...</td>\n",
       "      <td>2023-03-15 14:01:23+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "0     Presiden bertemu dengan timnas U-20 di GBK, Se...   \n",
       "1     Presiden Joko Widodo (Jokowi) melakukan kunjun...   \n",
       "2     Menteri Koordinator Politik, Hukum, dan Keaman...   \n",
       "3     JAKARTA - Cara tambah daya listrik hingga 5.50...   \n",
       "4     Sekretaris Jenderal PBNU Gus Saifullah Yusuf (...   \n",
       "...                                                 ...   \n",
       "5995  TEMPO.CO, Jakarta - Tim Pembela Prabowo-Gibran...   \n",
       "5996  Bakal calon Wakil Gubernur DKI Jakarta Rano Ka...   \n",
       "5997  Lembaga Survei Indonesia (LSI) mengungkapkan b...   \n",
       "5998   JAKARTA, KOMPAS.com - Jaksa Penuntut Umum (JP...   \n",
       "5999  JAKARTA  Cara daftar mudik gratis Kemenhub, BU...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Jokowi: Beberapa Pemain Timnas U-20 Ingin Kuli...   \n",
       "1     Kunker ke Lampung, Jokowi Akan Resmikan Bendun...   \n",
       "2     Mahfud Buat Satgas Tindak Lanjuti Rp 349 T, Di...   \n",
       "3     Tambah Daya Listrik hingga 5.500 VA dengan Bay...   \n",
       "4     Sekjen PBNU: Hubungan Santri dan Polri Baik, S...   \n",
       "...                                                 ...   \n",
       "5995  Hari Ini, Kubu Prabowo-Gibran Bakal Hadirkan 1...   \n",
       "5996  Rano Karno Ungkap Obrolan dengan Anies di Kant...   \n",
       "5997  Buah Kerja Keras Airin, Unggul di Semua Simula...   \n",
       "5998  Jaksa Bocorkan \"Chat\" Gazalba dengan Perempuan...   \n",
       "5999  Cara Daftar Mudik Gratis Kemenhub, BUMN dan Ja...   \n",
       "\n",
       "                               date  \n",
       "0            2023-04-01 10:36:35+00  \n",
       "1      Senin, 26 Agu 2024 08:53 WIB  \n",
       "2            2023-04-10 05:28:58+00  \n",
       "3            2023-03-23 02:41:24+00  \n",
       "4     Selasa, 03 Sep 2024 12:43 WIB  \n",
       "...                             ...  \n",
       "5995                       4/4/2024  \n",
       "5996    Rabu, 28 Agu 2024 12:16 WIB  \n",
       "5997   Kamis, 22 Agu 2024 11:45 WIB  \n",
       "5998                       8/8/2024  \n",
       "5999         2023-03-15 14:01:23+00  \n",
       "\n",
       "[6000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\berita_terkini.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46da9580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset setelah dibersihkan memiliki 5951 baris\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['content']).reset_index(drop=True).copy(deep=True)\n",
    "print(f\"Dataset setelah dibersihkan memiliki {len(df)} baris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec91b38c",
   "metadata": {},
   "source": [
    "PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1a02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(teks):\n",
    "    if not isinstance(teks, str):\n",
    "        return \"\"\n",
    "    teks = re.sub(r'<.*?>', ' ', teks)\n",
    "    teks = re.sub(r'https?://\\S+|www\\.\\S+', ' ', teks)\n",
    "    teks = re.sub(r'ADVERTISEMENT.*?CONTENT', ' ', teks, flags=re.IGNORECASE | re.DOTALL)\n",
    "    teks = re.sub(r'[^\\w\\s\\d]', ' ', teks)\n",
    "    teks = re.sub(r'\\s+', ' ', teks).strip()\n",
    "    return teks\n",
    "df['cleaned_text'] = df['content'].fillna('').apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9975cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(teks):\n",
    "    return teks.lower()\n",
    "df['case_folded_text'] = df['cleaned_text'].apply(case_folding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c7c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi(teks):\n",
    "    # Normalisasi angka (misalnya \"100 juta\" menjadi \"seratus juta\")\n",
    "    try:\n",
    "        # Gunakan normalize_text dari instance normalizer\n",
    "        teks = normalizer.normalize_text(teks)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat normalisasi angka: {e}\")\n",
    "        pass\n",
    "    slang_dict = {\n",
    "        'dgn': 'dengan',\n",
    "        'tdk': 'tidak',\n",
    "        'tsb': 'tersebut',\n",
    "        'utk': 'untuk',\n",
    "        'spy': 'supaya',\n",
    "        'krn': 'karena',\n",
    "        'jg': 'juga',\n",
    "        'bs': 'bisa',\n",
    "        'sdh': 'sudah',\n",
    "        'blm': 'belum',\n",
    "        'org': 'orang',\n",
    "        'yg': 'yang',\n",
    "        'sy': 'saya',\n",
    "        'dlm': 'dalam',\n",
    "        'pd': 'pada',\n",
    "        'dr': 'dari',\n",
    "        'kmrn': 'kemarin',\n",
    "        'skrg': 'sekarang',\n",
    "        'hrs': 'harus',\n",
    "        'msk': 'masuk',\n",
    "        'trs': 'terus',\n",
    "        'tp': 'tapi',\n",
    "        'kalo': 'kalau',\n",
    "        'gak': 'tidak',\n",
    "        'ga': 'tidak',\n",
    "        'ngga': 'tidak',\n",
    "        'gk': 'tidak',\n",
    "        'thn': 'tahun',\n",
    "        'bln': 'bulan',\n",
    "        'sblm': 'sebelum',\n",
    "        'stlh': 'setelah',\n",
    "        'milyar': 'miliar',\n",
    "        'trilliun': 'triliun',\n",
    "        'jt': 'juta',\n",
    "        'rb': 'ribu',\n",
    "        '%': 'persen',\n",
    "        'usd': 'dolar amerika',\n",
    "        'rupiah': 'rupiah',\n",
    "        'rp': 'rupiah',\n",
    "        ',': 'koma',\n",
    "    }\n",
    "    \n",
    "    # Buat pattern regex untuk seluruh kamus sekaligus (lebih efisien)\n",
    "    pattern = r'\\b(' + '|'.join(slang_dict.keys()) + r')\\b'\n",
    "    \n",
    "    # Fungsi replacement yang menggunakan kamus\n",
    "    def replace_match(match):\n",
    "        return slang_dict[match.group(0)]\n",
    "    \n",
    "    # Ganti semua kata slang dalam satu kali proses\n",
    "    return re.sub(pattern, replace_match, teks)\n",
    "df['normalized_text'] = df['case_folded_text'].apply(normalisasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6afe20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenzing(teks):\n",
    "    return word_tokenize(teks)\n",
    "df['tokens'] = df['normalized_text'].apply(tokenzing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fbba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_stopwords = set(stopwords.words('indonesian'))\n",
    "tambahan_stopwords = {\n",
    "    'ya', 'juga', 'dari', 'di', 'ke', 'pada', 'untuk', 'bagi', 'dan', 'atau', \n",
    "    'tapi', 'namun', 'dengan', 'secara', 'oleh', 'karena', 'sehingga', 'agar',\n",
    "    'sebab', 'jika', 'bila', 'adalah', 'ini', 'itu', 'detik', 'kata', 'dalam',\n",
    "    'saat', 'akan', 'tidak', 'yang', 'belum', 'sudah', 'telah', 'bisa', 'dapat', \n",
    "    'nya', 'pak', 'bu', 'hal', 'pun'\n",
    "}\n",
    "indo_stopwords.update(tambahan_stopwords)\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in indo_stopwords]\n",
    "df['filtered_tokens'] = df['tokens'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729eb111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stemming: 100%|██████████| 5951/5951 [1:20:34<00:00,  1.23it/s]  \n"
     ]
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "def stemming(tokens):\n",
    "    return [stemmer.stem(word) for word in tokens]\n",
    "df['stemmed_tokens'] = [stemming(tokens) for tokens in tqdm(df['filtered_tokens'], desc=\"Stemming\")]\n",
    "df['stemmed_text'] = df['stemmed_tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7cff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jokowi: Beberapa Pemain Timnas U-20 Ingin Kuli...</td>\n",
       "      <td>Presiden bertemu dengan timnas U-20 di GBK, Se...</td>\n",
       "      <td>presiden temu timnas u puluh gbk senayan sabtu...</td>\n",
       "      <td>2023-04-01 10:36:35+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunker ke Lampung, Jokowi Akan Resmikan Bendun...</td>\n",
       "      <td>Presiden Joko Widodo (Jokowi) melakukan kunjun...</td>\n",
       "      <td>presiden joko widodo jokowi kunjung kerja lamp...</td>\n",
       "      <td>Senin, 26 Agu 2024 08:53 WIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mahfud Buat Satgas Tindak Lanjuti Rp 349 T, Di...</td>\n",
       "      <td>Menteri Koordinator Politik, Hukum, dan Keaman...</td>\n",
       "      <td>menteri koordinator politik hukum aman menko p...</td>\n",
       "      <td>2023-04-10 05:28:58+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tambah Daya Listrik hingga 5.500 VA dengan Bay...</td>\n",
       "      <td>JAKARTA - Cara tambah daya listrik hingga 5.50...</td>\n",
       "      <td>jakarta daya listrik ratus va bayar rpdua ratu...</td>\n",
       "      <td>2023-03-23 02:41:24+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sekjen PBNU: Hubungan Santri dan Polri Baik, S...</td>\n",
       "      <td>Sekretaris Jenderal PBNU Gus Saifullah Yusuf (...</td>\n",
       "      <td>sekretaris jenderal pbnu gus saifullah yusuf g...</td>\n",
       "      <td>Selasa, 03 Sep 2024 12:43 WIB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Jokowi: Beberapa Pemain Timnas U-20 Ingin Kuli...   \n",
       "1  Kunker ke Lampung, Jokowi Akan Resmikan Bendun...   \n",
       "2  Mahfud Buat Satgas Tindak Lanjuti Rp 349 T, Di...   \n",
       "3  Tambah Daya Listrik hingga 5.500 VA dengan Bay...   \n",
       "4  Sekjen PBNU: Hubungan Santri dan Polri Baik, S...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Presiden bertemu dengan timnas U-20 di GBK, Se...   \n",
       "1  Presiden Joko Widodo (Jokowi) melakukan kunjun...   \n",
       "2  Menteri Koordinator Politik, Hukum, dan Keaman...   \n",
       "3  JAKARTA - Cara tambah daya listrik hingga 5.50...   \n",
       "4  Sekretaris Jenderal PBNU Gus Saifullah Yusuf (...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  presiden temu timnas u puluh gbk senayan sabtu...   \n",
       "1  presiden joko widodo jokowi kunjung kerja lamp...   \n",
       "2  menteri koordinator politik hukum aman menko p...   \n",
       "3  jakarta daya listrik ratus va bayar rpdua ratu...   \n",
       "4  sekretaris jenderal pbnu gus saifullah yusuf g...   \n",
       "\n",
       "                            date  \n",
       "0         2023-04-01 10:36:35+00  \n",
       "1   Senin, 26 Agu 2024 08:53 WIB  \n",
       "2         2023-04-10 05:28:58+00  \n",
       "3         2023-03-23 02:41:24+00  \n",
       "4  Selasa, 03 Sep 2024 12:43 WIB  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['processed_content'] = df['stemmed_text']\n",
    "display(df[['title', 'content', 'stemmed_text', 'date']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_new_file = r'D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\berita_terkini_preprocessing.csv'\n",
    "# preprocessing_new_columns = ['title', 'content', 'stemmed_text', 'date']\n",
    "# df[preprocessing_new_columns].to_csv(preprocessing_new_file, index=False)\n",
    "# print(f\"Hasil preprocessing berita terkini disimpan ke {preprocessing_new_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c31fb",
   "metadata": {},
   "source": [
    "PENGELOMPOKAN FAKTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f2c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kata_kunci = {\n",
    "    'suku_bunga': [\n",
    "        # Kata kunci spesifik\n",
    "        'suku bunga', 'interest rate', 'bi rate', 'bi7drrr', 'bank sentral', \n",
    "        'bank indonesia', 'bi', 'ojk', 'bank', 'inflasi', 'deflasi', 'yield', \n",
    "        'obligasi', 'federal reserve', 'deposito', 'kpr', 'tabungan', 'kredit', \n",
    "        'pinjaman', 'cicilan', 'dpk', 'ldr', 'blr', 'diskonto',\n",
    "        \n",
    "        # Tambahan kata kunci pasar modal\n",
    "        'ihsg', 'indeks harga saham gabungan', 'bei', 'bursa efek', 'saham', \n",
    "        'reksadana', 'obligasi', 'pasar modal', 'pasar saham', 'pasar uang',\n",
    "        'idx', 'composite index', 'jakarta composite index', 'jci',\n",
    "        \n",
    "        # Frasa kontekstual untuk suku bunga\n",
    "        'bunga kredit', 'bunga pinjaman', 'bunga acuan', 'bunga bank',\n",
    "        'bunga naik', 'bunga turun', 'bunga tetap', 'kebijakan moneter',\n",
    "        'pemangkasan bunga', 'kenaikan bunga', 'penurunan bunga', 'fed rate',\n",
    "        'the fed', 'tingkat bunga', 'acuan moneter', 'surat utang',\n",
    "        'likuiditas bank', 'dana pihak ketiga', 'kredit macet',\n",
    "        'bunga simpanan', 'bunga deposito', 'bi 7 day', 'bi7day',\n",
    "        \n",
    "        # Frasa dengan kata umum dalam konteks moneter\n",
    "        'suku bunga naik', 'suku bunga turun', 'inflasi naik', 'inflasi turun',\n",
    "        'kredit naik', 'kredit turun', 'bank sentral', 'bank tahan suku bunga',\n",
    "        'persen bunga', 'basis poin bunga', 'persentase kredit',\n",
    "        'persen inflasi', 'rasio kredit', 'tingkat kredit',\n",
    "        'rasio pinjaman', 'tingkat pinjaman', 'anggaran moneter',\n",
    "        'bps inflasi', 'persentase inflasi', 'ihsg naik', 'ihsg turun', \n",
    "        'ihsg kuat', 'ihsg lemah', 'indeks saham', 'indeks pasar'\n",
    "    ],\n",
    "    \n",
    "    'impor': [\n",
    "        # Kata kunci spesifik\n",
    "        'impor', 'import', 'importir', 'bea masuk', 'pelabuhan', 'bea cukai', 'bongkar muat',\n",
    "        'kontainer', 'container', 'harmonisasi tarif', 'barang impor', 'non migas', 'migas',\n",
    "        'barang modal', 'faktor produksi',\n",
    "        \n",
    "        # Frasa kontekstual untuk impor\n",
    "        'tarif impor', 'pajak impor', 'komoditas impor', 'produk impor',\n",
    "        'ketergantungan impor', 'pembatasan impor', 'larangan impor',\n",
    "        'kuota impor', 'izin impor', 'nilai impor', 'volume impor',\n",
    "        'peraturan impor', 'izin impor', 'dokumen impor',\n",
    "        'substitusi impor', 'neraca impor', 'bea impor',\n",
    "        'kebijakan impor', 'hambatan impor', 'proteksi impor',\n",
    "        \n",
    "        # Frasa spesifik produk\n",
    "        'impor beras', 'impor gula', 'impor daging', 'impor bbm', \n",
    "        'impor gandum', 'impor kedelai', 'impor bawang', 'impor garam', \n",
    "        'impor jagung', 'impor bahan pangan', 'impor bahan baku',\n",
    "        'impor bahan bakar', 'impor minyak', 'impor gas',\n",
    "        \n",
    "        # Frasa konteks ekonomi internasional\n",
    "        'neraca perdagangan', 'defisit perdagangan', 'surplus perdagangan',\n",
    "        'perdagangan bilateral', 'perjanjian perdagangan',\n",
    "        'komoditas luar negeri', 'belanja luar negeri', 'pembelian luar negeri'\n",
    "    ],\n",
    "    \n",
    "    'ekspor': [\n",
    "        # Kata kunci spesifik\n",
    "        'ekspor', 'export', 'eksportir', 'komoditas ekspor', 'non migas', 'migas',\n",
    "        'barang jadi', 'komoditas', 'fob', 'cpo', 'produk jadi', 'hilirisasi',\n",
    "        'kepabeanan', 'pengapalan', 'perdagangan luar negeri',\n",
    "        \n",
    "        # Frasa kontekstual untuk ekspor\n",
    "        'produk ekspor', 'nilai ekspor', 'volume ekspor', 'pasar ekspor',\n",
    "        'tujuan ekspor', 'pertumbuhan ekspor', 'penurunan ekspor', \n",
    "        'kenaikan ekspor', 'kebijakan ekspor', 'izin ekspor',\n",
    "        'dokumen ekspor', 'larangan ekspor', 'pembatasan ekspor',\n",
    "        'insentif ekspor', 'promosi ekspor', 'diversifikasi ekspor',\n",
    "        \n",
    "        # Frasa spesifik produk\n",
    "        'ekspor sawit', 'ekspor batu bara', 'ekspor nikel', 'ekspor karet',\n",
    "        'ekspor tekstil', 'ekspor manufaktur', 'ekspor pertanian',\n",
    "        'ekspor perikanan', 'ekspor kayu', 'ekspor mineral', 'ekspor logam',\n",
    "        'ekspor produk jadi', 'ekspor komoditas unggulan',\n",
    "        \n",
    "        # Frasa konteks ekonomi internasional\n",
    "        'perdagangan internasional', 'neraca perdagangan', 'surplus perdagangan',\n",
    "        'defisit perdagangan', 'devisa negara', 'penghasil devisa', 'penerimaan negara',\n",
    "        'hambatan ekspor', 'tarif ekspor', 'proteksionisme', 'pasar global',\n",
    "        'pasar dunia', 'pengiriman barang', 'negara tujuan ekspor'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming kamus kata kunci dengan pengelompokan yang lebih baik\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "stemmed_kata_kunci = {}\n",
    "for kategori, keywords in kata_kunci.items():\n",
    "    stemmed_keywords = []\n",
    "    for keyword in keywords:\n",
    "        if ' ' in keyword:  # Kata majemuk\n",
    "            stemmed_parts = [stemmer.stem(word) for word in keyword.split()]\n",
    "            stemmed_keywords.append(' '.join(stemmed_parts))\n",
    "        else:  # Kata tunggal\n",
    "            stemmed_keywords.append(stemmer.stem(keyword))\n",
    "    stemmed_kata_kunci[kategori] = stemmed_keywords\n",
    "\n",
    "# Dictionary untuk konteks kata-kata umum yang perlu pemeriksaan tambahan\n",
    "kata_umum_konteks = {\n",
    "    'naik': ['bunga', 'suku', 'inflasi', 'kredit', 'pinjam', 'moneter', 'bank', 'ekonomi', 'ihsg', 'indeks', 'saham', 'rupiah'],\n",
    "    'turun': ['bunga', 'suku', 'inflasi', 'kredit', 'pinjam', 'moneter', 'bank', 'ekonomi', 'ihsg', 'indeks', 'saham', 'rupiah'],\n",
    "    'tetap': ['bunga', 'suku', 'inflasi', 'kredit', 'pinjam', 'moneter', 'bank', 'ihsg', 'indeks', 'saham', 'rupiah'],\n",
    "    'persen': ['bunga', 'suku', 'inflasi', 'kredit', 'pinjam', 'moneter', 'bank', 'ihsg', 'indeks', 'saham'],\n",
    "    'tingkat': ['bunga', 'suku', 'inflasi', 'kredit', 'pinjam', 'moneter', 'ihsg', 'indeks', 'saham'],\n",
    "    'nilai': ['impor', 'ekspor', 'perdagang', 'komoditas', 'ihsg', 'indeks', 'saham', 'rupiah'],\n",
    "    'masuk': ['bea', 'impor', 'barang', 'komoditas'],\n",
    "    'kuota': ['impor', 'ekspor', 'perdagang', 'komoditas'],\n",
    "    'pasar': ['ekspor', 'impor', 'global', 'dunia', 'komoditas', 'modal', 'saham', 'uang'],\n",
    "    'harmonisasi': ['tarif', 'impor', 'perdagang', 'bea'],\n",
    "    'kapal': ['ekspor', 'perdagang', 'komoditas', 'pengapal'],\n",
    "    'terima': ['devisa', 'negara', 'ekspor'],\n",
    "    'hilir': ['ekspor', 'komoditas', 'produk'],\n",
    "    'kuat': ['ihsg', 'saham', 'indeks', 'pasar', 'rupiah'],\n",
    "    'lemah': ['ihsg', 'saham', 'indeks', 'pasar', 'rupiah']\n",
    "}\n",
    "# Fungsi yang disempurnakan untuk memeriksa apakah teks mengandung kata kunci\n",
    "def cek_kategori_konteks(teks, kategori_keywords, kata_umum_konteks):\n",
    "    \"\"\"\n",
    "    Memeriksa apakah teks mengandung kata kunci dari kategori tertentu,\n",
    "    dengan pemeriksaan konteks tambahan untuk kata-kata umum.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    # Untuk mengecek konteks, kita pisahkan teks menjadi kata-kata\n",
    "    kata_teks = teks.split()\n",
    "    for keyword in kategori_keywords:\n",
    "        # Cek apakah keyword adalah kata umum yang memerlukan pengecekan konteks\n",
    "        is_umum = False\n",
    "        for kata_umum in kata_umum_konteks:\n",
    "            if kata_umum == keyword:\n",
    "                is_umum = True\n",
    "                break              \n",
    "        if ' ' in keyword:  # Kata majemuk - cek sebagai frasa\n",
    "            if keyword in teks:\n",
    "                matches.append(keyword)\n",
    "        else:  # Kata tunggal\n",
    "            pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "            match = re.search(pattern, teks)\n",
    "            if match:\n",
    "                # Jika kata umum, cek konteks\n",
    "                if is_umum:\n",
    "                    # Cari posisi kata dalam teks\n",
    "                    for i, kata in enumerate(kata_teks):\n",
    "                        if re.search(pattern, kata):\n",
    "                            # Ambil konteks (5 kata sebelum dan 5 kata sesudah)\n",
    "                            start = max(0, i - 5)\n",
    "                            end = min(len(kata_teks), i + 6)\n",
    "                            konteks = kata_teks[start:end]\n",
    "                            \n",
    "                            # Cek apakah ada kata konteks dalam window\n",
    "                            konteks_relevan = kata_umum_konteks.get(keyword, [])\n",
    "                            if any(re.search(r'\\b' + re.escape(k) + r'\\b', ' '.join(konteks)) for k in konteks_relevan):\n",
    "                                matches.append(keyword)\n",
    "                                break\n",
    "                else:\n",
    "                    # Bukan kata umum, langsung tambahkan\n",
    "                    matches.append(keyword)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4834ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mengkategorikan berita...\n",
      "Mengkategorikan untuk kategori suku_bunga...\n",
      "Mengkategorikan untuk kategori impor...\n",
      "Mengkategorikan untuk kategori ekspor...\n",
      "\n",
      "Jumlah berita per kategori:\n",
      "suku_bunga: 560 berita\n",
      "impor: 374 berita\n",
      "ekspor: 256 berita\n"
     ]
    }
   ],
   "source": [
    "# Kategorisasi berita\n",
    "print(\"Mengkategorikan berita...\")\n",
    "for kategori, keywords in stemmed_kata_kunci.items():\n",
    "    print(f\"Mengkategorikan untuk kategori {kategori}...\")\n",
    "    \n",
    "    # Tambahkan kolom untuk keyword yang ditemukan\n",
    "    df[f\"{kategori}_keywords\"] = df['stemmed_text'].apply(\n",
    "        lambda x: cek_kategori_konteks(x, keywords, kata_umum_konteks)\n",
    "    )\n",
    "    \n",
    "    # Tambahkan kolom boolean untuk kategori\n",
    "    df[kategori] = df[f\"{kategori}_keywords\"].apply(lambda x: len(x) > 0)\n",
    "\n",
    "# Hitung statistik kategorisasi\n",
    "print(\"\\nJumlah berita per kategori:\")\n",
    "for kategori in stemmed_kata_kunci.keys():\n",
    "    jumlah = df[kategori].sum()\n",
    "    print(f\"{kategori}: {jumlah} berita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f329a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jumlah berita per kategori:\n",
      "suku_bunga: 560 berita\n",
      "impor: 374 berita\n",
      "ekspor: 256 berita\n"
     ]
    }
   ],
   "source": [
    "#Membuat kolom faktor\n",
    "def get_faktor(row):\n",
    "    faktor = []\n",
    "    for kategori in stemmed_kata_kunci.keys():\n",
    "        if row[kategori]:\n",
    "            faktor.append(kategori)\n",
    "    return faktor\n",
    "df['faktor'] = df.apply(get_faktor, axis=1)\n",
    "\n",
    "# Menambahkan kolom yang mencatat kata kunci spesifik yang ditemukan\n",
    "def get_keyword_details(row):\n",
    "    details = {}\n",
    "    for kategori in stemmed_kata_kunci.keys():\n",
    "        if row[kategori] and len(row[f\"{kategori}_keywords\"]) > 0:\n",
    "            details[kategori] = row[f\"{kategori}_keywords\"]\n",
    "    return details\n",
    "df['keyword_details'] = df.apply(get_keyword_details, axis=1)\n",
    "\n",
    "print(\"\\nJumlah berita per kategori:\")\n",
    "for kategori in stemmed_kata_kunci.keys():\n",
    "    jumlah = df[kategori].sum()\n",
    "    print(f\"{kategori}: {jumlah} berita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d068391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribusi detail kategori:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'suku_bunga'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'suku_bunga'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-cddef10ef922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Distribusi detail\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nDistribusi detail kategori:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Hanya suku_bunga: {len(df[(df['suku_bunga']==True) & (df['impor']==False) & (df['ekspor']==False)])}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Hanya impor: {len(df[(df['suku_bunga']==False) & (df['impor']==True) & (df['ekspor']==False)])}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Hanya ekspor: {len(df[(df['suku_bunga']==False) & (df['impor']==False) & (df['ekspor']==True)])}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'suku_bunga'"
     ]
    }
   ],
   "source": [
    "# Distribusi detail\n",
    "print(\"\\nDistribusi detail kategori:\")\n",
    "print(f\"Hanya suku_bunga: {len(df[(df['suku_bunga']==True) & (df['impor']==False) & (df['ekspor']==False)])}\")\n",
    "print(f\"Hanya impor: {len(df[(df['suku_bunga']==False) & (df['impor']==True) & (df['ekspor']==False)])}\")\n",
    "print(f\"Hanya ekspor: {len(df[(df['suku_bunga']==False) & (df['impor']==False) & (df['ekspor']==True)])}\")\n",
    "print(f\"suku_bunga dan impor: {len(df[(df['suku_bunga']==True) & (df['impor']==True) & (df['ekspor']==False)])}\")\n",
    "print(f\"suku_bunga dan ekspor: {len(df[(df['suku_bunga']==True) & (df['impor']==False) & (df['ekspor']==True)])}\")\n",
    "print(f\"impor dan ekspor: {len(df[(df['suku_bunga']==False) & (df['impor']==True) & (df['ekspor']==True)])}\")\n",
    "print(f\"semua kategori: {len(df[(df['suku_bunga']==True) & (df['impor']==True) & (df['ekspor']==True)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298fa9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Berita yang tidak masuk kategori: 4968\n",
      "Berita yang masuk 1 kategori: 800\n",
      "Berita yang masuk 2 kategori: 159\n",
      "Berita yang masuk 3 kategori: 24\n"
     ]
    }
   ],
   "source": [
    "df['jumlah_kategori'] = df[list(stemmed_kata_kunci.keys())].sum(axis=1)\n",
    "print(f\"\\nBerita yang tidak masuk kategori: {len(df[df['jumlah_kategori'] == 0])}\")\n",
    "print(f\"Berita yang masuk 1 kategori: {len(df[df['jumlah_kategori'] == 1])}\")\n",
    "print(f\"Berita yang masuk 2 kategori: {len(df[df['jumlah_kategori'] == 2])}\")\n",
    "print(f\"Berita yang masuk 3 kategori: {len(df[df['jumlah_kategori'] == 3])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00249477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah berita setelah menghapus yang tidak berkategori: 983\n"
     ]
    }
   ],
   "source": [
    "# Menghapus berita yang tidak masuk ke kategori apapun\n",
    "df_filtered = df[df['jumlah_kategori'] > 0].copy()\n",
    "print(f\"Jumlah berita setelah menghapus yang tidak berkategori: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd6efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil pengelompokan telah disimpan ke D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\berita_terkini_berkategori.csv\n"
     ]
    }
   ],
   "source": [
    "# # Menyimpan hasil kategori ke file CSV baru\n",
    "# output_file = r'D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\berita_terkini_berkategori.csv'\n",
    "# # Mengonversi kolom faktor dan keyword_details (dict/list) menjadi string agar bisa disimpan di CSV\n",
    "# df_filtered['faktor_str'] = df_filtered['faktor'].apply(lambda x: str(x))\n",
    "# df_filtered['keyword_details_str'] = df_filtered['keyword_details'].apply(lambda x: str(x))\n",
    "# df_output = df_filtered[['title', 'content', 'date', 'faktor_str', 'jumlah_kategori', 'keyword_details_str']]\n",
    "# df_output.to_csv(output_file, index=False)\n",
    "# print(f\"Hasil pengelompokan telah disimpan ke {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ebeb42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil preprocessing (hanya berita berkategori) disimpan ke D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\fix_berita_terkini.csv\n"
     ]
    }
   ],
   "source": [
    "preprocessing_file = (r'D:\\SKRIPSI\\skripsi_2025\\fix_dataset\\fix_berita_terkini.csv')\n",
    "preprocessing_columns = ['title', 'content','stemmed_text', 'faktor_str', 'date']\n",
    "df_filtered[preprocessing_columns].to_csv(preprocessing_file, index=False)\n",
    "print(f\"Hasil preprocessing (hanya berita berkategori) disimpan ke {preprocessing_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aad93fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampel berita dari setiap kategori:\n",
      "\n",
      "=== SAMPEL BERITA SUKU_BUNGA ===\n",
      "Judul: AS Kucilkan RI Perkara Nikel, Jokowi Gak Tinggal Diam..\n",
      "Tanggal: 2023-04-07 03:05:00+00\n",
      "Faktor: ['suku_bunga', 'impor', 'ekspor']\n",
      "Kata kunci yang ditemukan: {'suku_bunga': ['kredit'], 'impor': ['janji dagang'], 'ekspor': ['dagang internasional']}\n",
      "---\n",
      "Judul: Viral Pemotor Curi 2 Tabung Gas di Warung Daerah Depok, Polisi Selidiki\n",
      "Tanggal: Kamis, 04 Jul 2024 18:57 WIB\n",
      "Faktor: ['suku_bunga']\n",
      "Kata kunci yang ditemukan: {'suku_bunga': ['tabung']}\n",
      "---\n",
      "Judul: Rahmat Waluyanto, dari Sarjana Ekonomi UGM Hingga Wakil Ketua OJK\n",
      "Tanggal: 2023-04-10 04:38:42+00\n",
      "Faktor: ['suku_bunga']\n",
      "Kata kunci yang ditemukan: {'suku_bunga': ['ojk', 'obligasi', 'surat utang']}\n",
      "---\n",
      "\n",
      "=== SAMPEL BERITA IMPOR ===\n",
      "Judul: Cara Daftar Mudik Gratis 2023 Kapal Laut, Dibuka 23 Maret untuk 5000 Penumpang!\n",
      "Tanggal: 2023-03-22 01:05:00+00\n",
      "Faktor: ['impor']\n",
      "Kata kunci yang ditemukan: {'impor': ['labuh']}\n",
      "---\n",
      "Judul: Warga Resah Ribuan Truk Lalu Lalang di Jalan Plumpang Tiap Hari, Sering Makan Korban Jiwa\n",
      "Tanggal: 5/9/2024\n",
      "Faktor: ['impor']\n",
      "Kata kunci yang ditemukan: {'impor': ['kontainer']}\n",
      "---\n",
      "Judul: Pernyataan Dirut Pertamina soal Hasil Investigasi Kebakaran Depo BBM Plumpang\n",
      "Tanggal: 2023-03-16 05:29:24+00\n",
      "Faktor: ['impor', 'ekspor']\n",
      "Kata kunci yang ditemukan: {'impor': ['migas'], 'ekspor': ['migas']}\n",
      "---\n",
      "\n",
      "=== SAMPEL BERITA EKSPOR ===\n",
      "Judul: Jelang Lebaran Jokowi Blusukan ke Pasar Lagi: Disini Bahan Pokok Paling Murah\n",
      "Tanggal: 2023-04-06 10:45:05+00\n",
      "Faktor: ['ekspor']\n",
      "Kata kunci yang ditemukan: {'ekspor': ['komoditas']}\n",
      "---\n",
      "Judul: Jokowi Kesal Baju Bekas Impor Masih Marak, Ternyata Begini Cara Impornya\n",
      "Tanggal: 2023-03-16 01:07:00+00\n",
      "Faktor: ['impor', 'ekspor']\n",
      "Kata kunci yang ditemukan: {'impor': ['impor', 'importir', 'labuh', 'bea cukai', 'larang impor'], 'ekspor': ['ekspor', 'pabean']}\n",
      "---\n",
      "Judul: Ribuan Ton Pakaian Bekas Masuk Indonesia Tiap Tahun, Asosiasi Tekstil: Paling Banyak dari Malaysia\n",
      "Tanggal: 2023-04-01 08:05:08+00\n",
      "Faktor: ['impor', 'ekspor']\n",
      "Kata kunci yang ditemukan: {'impor': ['impor', 'importir', 'larang impor', 'izin impor', 'izin impor'], 'ekspor': ['ekspor']}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSampel berita dari setiap kategori:\")\n",
    "for kategori in stemmed_kata_kunci.keys():\n",
    "    print(f\"\\n=== SAMPEL BERITA {kategori.upper()} ===\")\n",
    "    if df[df[kategori]].shape[0] > 0:\n",
    "        sampel = df[df[kategori]].sample(min(3, df[df[kategori]].shape[0]))\n",
    "        for idx, row in sampel.iterrows():\n",
    "            print(f\"Judul: {row['title']}\")\n",
    "            print(f\"Tanggal: {row['date']}\")\n",
    "            print(f\"Faktor: {row['faktor']}\")\n",
    "            print(f\"Kata kunci yang ditemukan: {row['keyword_details']}\")\n",
    "            print(\"---\")\n",
    "    else:\n",
    "        print(\"Tidak ada berita dalam kategori ini.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e71eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
